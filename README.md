# Hi, I'm Varshitha Gudimalla ğŸ‘‹

**Data Engineer** | AWS | Azure | Databricks | PySpark | SQL

varshithag1908@gmail.com | [LinkedIn](https://linkedin.com/in/varshitha-gudimalla-data-engineer) | [Portfolio](https://varshitha-g.github.io/portfolio/)

---

**ğŸ“ Education:** MS in Data Science (University at Albany, 2025) | BTech in Computer Science (CMR Institute, 2022)

---

## ğŸ’¼ Current Role

**Data Engineer @ FedEx** *(Jan 2025 - Present)*

Building real-time logistics data platform serving 40+ analytics and ML teams:

- AWS lakehouse processing **10-50TB daily** â†’ Cut ETL time from 5 hours to 2 hours
- Real-time streaming with Kinesis â†’ **$2M+ fraud prevention annually**
- 50+ Airflow DAGs â†’ **99.9% pipeline reliability**
- Data quality framework â†’ Passed SOC 2 audit, reduced costs 22%

---

## ğŸ› ï¸ Tech Stack

```yaml
Cloud Platforms:
  - AWS: S3, Glue, Redshift, Kinesis, Lambda, EMR, Athena, CloudWatch
  - Azure: Databricks, Data Factory, Synapse Analytics, ADLS Gen2, DevOps
  - Snowflake

Big Data & Processing:
  - PySpark, Apache Spark, Spark SQL, Delta Lake, Hadoop, Hive

Programming:
  - Python (Pandas, NumPy, scikit-learn)
  - SQL (Advanced CTEs, Window Functions, Query Optimization)
  - Scala

Data Engineering:
  - ETL/ELT Pipelines, Data Lakes, Data Warehouses
  - CDC, SCD Type-2, Star/Snowflake Schema

Orchestration & Streaming:
  - Apache Airflow, Apache Kafka, AWS Kinesis, Jenkins

DevOps & Quality:
  - Git/GitHub, CI/CD, Docker, Terraform
  - Great Expectations, HIPAA/GDPR Compliance

Visualization:
  - Power BI, Tableau, Dashboard Development
```

---

## ğŸ“ˆ Featured Projects

### ğŸŒ Real-Time Economic Intelligence Platform
**Problem:** Analysts spending 5 days manually compiling inflation data from 190+ countries  
**Solution:** Built Spark + Snowflake pipeline processing 2M+ daily economic indicators  
**Impact:** 80% time reduction (5 days â†’ 4 hours), enabling faster policy decisions  
**Tech:** `PySpark` `Snowflake` `REST APIs` `Airflow` `Python`

---

### ğŸ“ ML-Powered Customer Retention System
**Problem:** Telecom losing 25% of customers annually with no early warning system  
**Solution:** End-to-end ML pipeline analyzing 500K+ customer behavioral patterns  
**Impact:** 87% prediction accuracy, saved **$2.3M annually**  
**Tech:** `PySpark` `Databricks` `scikit-learn` `Airflow` `Delta Lake`

---

## ğŸ¯ Career Highlights

| Year | Milestone | Impact |
|------|-----------|--------|
| **2025** | Data Engineer @ FedEx | Processing 1B+ daily records, $2M+ fraud prevention |
| **2025** | MS Data Science | University at Albany (completed while working full-time) |
| **2022-23** | Data Engineer @ Knowledge Solutions | $4.8M revenue retained through ML churn prediction |
| **2021-22** | Data Engineer @ CloudEnd Platform | Zero HIPAA violations, 10-12% treatment improvement |
| **2022** | BTech Computer Science | CMR Institute of Technology, India |

---

## ğŸ“Š GitHub Stats

![Varshitha's GitHub stats](https://github-readme-stats.vercel.app/api?username=varshitha-g&show_icons=true&theme=blue-green&hide_border=true)

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=varshitha-g&layout=compact&theme=blue-green&hide_border=true)
---

## ğŸŒŸ What I'm Working On

- ğŸ”­ Building real-time data platforms at FedEx
- ğŸŒ± Exploring advanced streaming architectures with Kafka and Flink
- ğŸ“š Contributing to open-source data engineering tools
- ğŸ’¡ Writing about data engineering best practices

---

## ğŸ“« Let's Connect

I'm actively seeking new opportunities in Data Engineering focused on cloud platforms, real-time processing, and scalable data architecture.

- ğŸ“§ Email: [varshithag1908@gmail.com](mailto:varshithag1908@gmail.com)
- ğŸ’¼ LinkedIn: [varshitha-gudimalla-data-engineer](https://linkedin.com/in/varshitha-gudimalla-data-engineer)
- ğŸŒ Portfolio: [varshitha-g.github.io/portfolio](https://varshitha-g.github.io/portfolio/)


---

## ğŸ’¡ Fun Facts

- âš™ï¸ Built my first ETL pipeline processing patient data while ensuring HIPAA compliance
- ğŸ“ Completed MS in Data Science while working full-time as a Data Engineer
- ğŸ“Š Processed over 1 billion records in a single day at FedEx
- ğŸš€ Reduced data processing time from 5 hours to 2 hours through optimization

---

<div align="center">

### â­ If you find my work interesting, feel free to star my repositories!

**Currently employed at FedEx | Actively exploring new opportunities**

</div>
